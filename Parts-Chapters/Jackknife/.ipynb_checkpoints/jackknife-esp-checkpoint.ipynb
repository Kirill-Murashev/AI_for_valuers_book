{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00683ed",
   "metadata": {},
   "source": [
    "# Superación del problema de las estimaciones sesgadas al analizar datos de mercados abiertos mediante el método de remuestreo Jackknife"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b4eb2",
   "metadata": {},
   "source": [
    "Cyrill A. Murashev, 2023-02-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc51b3",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3067f10",
   "metadata": {},
   "source": [
    "Los tasadores se enfrentan a menudo a la necesidad de analizar y describir datos de mercado recogidos en los mercados abiertos. Casi siempre no pueden obtener los datos de todo el mercado, sino que tratan con muestras, que pueden ser muy pequeñas en relación con toda la población general. En este caso, surge el problema de las estimaciones sesgadas. De lo anterior se deduce que cualquier estimación estadística realizada a partir de la muestra en cuestión es una estimación para la propia muestra. Al mismo tiempo, puede tener un sesgo en relación con la estimación que se obtendría en el caso de un análisis de toda la población general. Los tasadores suelen decir que han calculado algunas estadísticas descriptivas del mercado. Puede tratarse de la media o mediana del precio, el máximo y el mínimo, etc. Pero debemos entender que son sólo estimaciones para muestras, no para todo el mercado. Hoy estudiaremos las bases teóricas mínimas del método. Y luego lo aplicaremos a datos reales del mercado utilizando el lenguaje Python. Aprenderemos a determinar para cualquier estimación si existe sesgo y a reducir automáticamente su componente lineal. Este documento tiene versiones en [inglés](https://github.com/Kirill-Murashev/AI_for_valuers_book/blob/main/Parts-Chapters/Jackknife/jackknife.ipynb), [español](https://github.com/Kirill-Murashev/AI_for_valuers_book/blob/main/Parts-Chapters/Jackknife/jackknife-esp.ipynb) y [ruso](https://github.com/Kirill-Murashev/AI_for_valuers_book/blob/main/Parts-Chapters/Jackknife/jackknife-nov.ipynb). La versión más actualizada y rápida es la inglesa. Si hay discrepancias entre versiones, debe confiarse en la versión inglesa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b687ef4",
   "metadata": {},
   "source": [
    "## Bases del método Jackknife"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10984e68",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b4ef7",
   "metadata": {},
   "source": [
    "En primer lugar, debemos recordar por qué los tasadores necesitan estadísticas. Suelen tener una cierta distribución de las características de los objetos a partir de la muestra de análogos recogidos en el mercado abierto. Y tratan de obtener algunas estimaciones de los valores de esas características. Puede ser la media, la mediana, el máximo, el mínimo, la varianza, etc. A veces también necesitan comparar dos o más submuestras para decidir si es necesario realizar algunos ajustes en función de la diferencia de valores de las características. Como podemos adivinar, la mayoría de las veces los tasadores trabajan con muestras, no con todo el mercado. Por lo tanto, los tasadores sólo pueden obtener estimaciones muestrales de los valores de las características, pero no sus valores reales. \n",
    "El método de Jackknife puede gestionar dos cuestiones:\n",
    "- reducir el sesgo de la estimación muestral con respecto al valor real de la población general;\n",
    "- calcular la varianza del valor ajustado de la característica.\n",
    "\n",
    "Supongamos que tenemos alguna característica *X* (podría ser el precio unitario, por ejemplo), cuya distribución en la población general desconocemos. Pero tenemos una muestra formada por n elementos $[x{1},\\ldots, x_{n}]$. Queremos estimar la expectativa de *X* que se puede escribir como $\\mathbb{E}[X]$. En general, la expectativa puede expresarse del siguiente modo\n",
    "$$\\mathbb{E}[X] = \\sum_{j=1}^{n >> 1} p(x_{j})x_{j}.$$\n",
    "\n",
    "Pero sólo tenemos una muestra que, por supuesto, consiste en un número muy limitado de observaciones, lejos del infinito. Por tanto, no podemos estimar la expectativa, sólo la media muestral que se anota como\n",
    "$$\\hat{\\mu}=\\dfrac{1}{n} \\sum_{i=1}^{n<<\\infty}x_{i}.$$\n",
    "\n",
    "Por lo tanto, no utilizamos probabilidades, sino frecuencias observadas. Es evidente que $\\mathbb{E}[X] \\neq \\hat{\\mu}$, pero $\\hat{\\mu} = \\mathbb{E}[X] + \\mathcal{bias}$, donde $\\mu$ es la estimación de la expectativa, y el sesgo es algún desplazamiento sistemático entre los valores verdadero y estimado de la expectativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7de898",
   "metadata": {},
   "source": [
    "### Concepto general del método Jacknife"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845785ef",
   "metadata": {},
   "source": [
    "Hemos considerado un caso especial. Ahora podemos pasar al concepto más general de sesgo del estimador. Consideremos la variable aleatoria *X* que tiene la distribución desconocida *U*. Existe un parámetro de su distribución denominado $\\theta$. Y nuestro objetivo es determinar su valor. El uso del parámetro abstracto $\\theta$ en lugar de uno específico pone de relieve la universalidad del método Jackknife, que es capaz de detectar sesgos para cualquier parámetro de la distribución y corregir automáticamente su componente lineal. También tenemos el parámetro $\\hat{\\theta}$, que es la estimación de muestreo obtenida al utilizar alguna función. Debido al hecho de que $\\hat{\\theta}$ se obtuvo de una muestra, mientras que nuestro objetivo es estimar $\\theta$ para la población general, es decir, todo el mercado en el contexto de la valoración, $\\hat{\\theta}$ tiene un sesgo en relación con $\\theta$. Matemáticamente, significa que la expectativa para $\\hat{\\theta}$ no es igual a la expectativa para $\\theta$:\n",
    "$$\\mathbb{E}(\\hat{\\theta}) \\neq \\mathbb{E}(\\theta).$$\n",
    "En este caso, podemos decir que\n",
    "$$\\mathbb{E}(\\hat{\\theta}_{n}) = \\theta + \\frac{\\alpha}{n} + \\frac{\\beta}{n^{2}} + \\frac{\\gamma}{n^{3}} + \\ldots \\frac{\\omega}{n^{(k\\rightarrow \\infty)}},$$\n",
    "donde $\\theta$ es el valor verdadero del parámetro para la población general, e $\\frac{\\alpha}{n} + \\frac{\\beta}{n^{2}} + \\frac{\\gamma}{n^{3}} + \\ldots \\frac{\\omega}{n^{(k\\rightarrow \\infty)}}$ son los componentes lineales, cuadráticos, cúbicos y otros del sesgo. Todos los componentes disminuyen con el crecimiento de la muestra de acuerdo con funciones lineales, cuadráticas, cúbicas y otras. El término lineal introduce el mayor error porque es el que disminuye más lentamente de todos los demás.\n",
    "\n",
    "El método Jackknife elimina el componente lineal del sesgo. Introduzcamos nuevas definiciones.\n",
    "\n",
    "$\\hat{\\theta}_{i}$ es el valor de $\\hat{\\theta}$ que se obtendría al calcular no sobre una muestra completa, sino sobre una muestra con una observación excluida *i*, que toma valores de 1 a *n*. Entonces\n",
    "$$\\mathbb{E}(\\hat{\\theta}_{(i)}) = \\theta + \\frac{\\alpha}{n-1} + \\frac{\\beta}{(n-1)^{2}} + \\frac{\\gamma}{(n-1)^{3}} + \\ldots \\frac{\\omega}{(n-1)^{(k\\rightarrow \\infty)}}.$$\n",
    "$\\overline{\\theta}$ es el valor medio de todos los $\\hat{\\theta}_{i}$.\n",
    "$$\\overline{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\theta}_{i}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709fcf5",
   "metadata": {},
   "source": [
    "### Sumario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53e0e8",
   "metadata": {},
   "source": [
    "Por lo tanto, para aplicar el método Jackknife, es decir, detectar la presencia de un sesgo y eliminar automáticamente su componente lineal, se requiere el siguiente conjunto de pasos.\n",
    "1. Necesitamos estimar algún parámetro $\\theta$ de una variable aleatoria *X*.\n",
    "1. Obtengamos alguna estimación de $\\hat{\\theta}$ para la muestra utilizando alguna función matemática $\\hat{\\theta}=F(x_{1},\\ldots,x_{n})$.\n",
    "1. $\\hat{\\theta}$ puede ser parcial.\n",
    "1. $\\theta = \\mathbb{E}(\\hat{\\theta}) + bias$.\n",
    "1. Creemos las nuevas *n* muestras mediante la exclusión secuencial de una *x* de la muestra inicial.\n",
    "1. Calcular la $\\hat{\\theta}_{(i)}$ para todas las nuevas muestras utilizando la misma función **F**.\n",
    "1. Calcula la media de todas las $\\hat{\\theta}_{(i)}$ y dénotala como $\\overline{\\theta}$.\n",
    "1. Calcule el sesgo mediante la siguiente fórmula\n",
    "$$\\widehat{bias}_{jack} = (n-1)(\\overline{\\theta} - \\hat{\\theta}).$$\n",
    "1. Elimine el componente lineal del sesgo mediante la fórmula\n",
    "$$\\hat{\\theta}_{jacked} = \\hat{\\theta} - \\widehat{bias}_{jack}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88cf6e",
   "metadata": {},
   "source": [
    "## Aplicación práctica en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e084ff",
   "metadata": {},
   "source": [
    "Hoy utilizaremos un conjunto de datos que contiene 34821 observaciones del mercado inmobiliario residencial de San Petersburgo. Se obtuvo del web-scrapping en septiembre de 2021. Supongamos que este conjunto de datos contiene datos sobre todo el mercado, por lo que podemos utilizarlo como población general. A continuación, crearemos una submuestra que contenga sólo 25 observaciones, lo que refleja el número típico de observaciones que maneja un tasador. Calcularemos “la expectativa” de nuestra “población general” y, a continuación, calcularemos la media de la muestra. Por último, aplicaremos el método Jackknife y compararemos su resultado del cálculo de la media en relación con la media muestral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df71016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats import jackknife_resampling\n",
    "from astropy.stats import jackknife_stats\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "805cc253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                     links   price_m  county\n",
      "0               1  https://spb.cian.ru/sale/flat/262765174/  155460.0  sadadm\n",
      "1               2  https://spb.cian.ru/sale/flat/263280601/  295455.0  sadadm\n",
      "2               3  https://spb.cian.ru/sale/flat/261612519/  310559.0  sadadm\n",
      "3               4  https://spb.cian.ru/sale/flat/263094016/  100000.0  sadadm\n",
      "4               5  https://spb.cian.ru/sale/flat/262339898/  145929.0  sadadm\n",
      "...           ...                                       ...       ...     ...\n",
      "34816       34817  https://spb.cian.ru/sale/flat/256621764/   70093.0  llobol\n",
      "34817       34818  https://spb.cian.ru/sale/flat/261430727/   67227.0  llobol\n",
      "34818       34819  https://spb.cian.ru/sale/flat/246538655/   86207.0  llobol\n",
      "34819       34820  https://spb.cian.ru/sale/flat/246587468/   65455.0  llobol\n",
      "34820       34821  https://spb.cian.ru/sale/flat/239698989/   89041.0  llobol\n",
      "\n",
      "[34821 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"spba-flats-210928.csv\", index_col=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9899bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of unit price for 'general population' is 176116.52505671864\n",
      "The maximum of unit price for 'general population' is 1624829.0\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and maximum for the \"general population\"\n",
    "gp_mean = df['price_m'].mean()\n",
    "gp_max = df['price_m'].max()\n",
    "print(\"The mean of unit price for 'general population' is\", gp_mean)\n",
    "print(\"The maximum of unit price for 'general population' is\", gp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c32eb719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                     links   price_m  county\n",
      "20606       20607  https://spb.cian.ru/sale/flat/264064476/  213889.0  sprkol\n",
      "11160       11161  https://spb.cian.ru/sale/flat/261519367/  161667.0  skryuz\n",
      "21112       21113  https://spb.cian.ru/sale/flat/263895261/  148830.0  sprlax\n",
      "19612       19613  https://spb.cian.ru/sale/flat/250041085/  189706.0  sprn65\n",
      "5076         5077  https://spb.cian.ru/sale/flat/263660571/  139382.0  skapis\n",
      "13890       13891  https://spb.cian.ru/sale/flat/263013521/  231935.0  smonow\n",
      "12315       12316  https://spb.cian.ru/sale/flat/262914352/  198765.0  smozwy\n",
      "8250         8251  https://spb.cian.ru/sale/flat/263518941/  181985.0  skrpol\n",
      "243           244  https://spb.cian.ru/sale/flat/251281327/  210697.0  sadeka\n",
      "15608       15609  https://spb.cian.ru/sale/flat/260189091/  134454.0  snenew\n",
      "7387         7388  https://spb.cian.ru/sale/flat/257597416/  108974.0  skomet\n",
      "5179         5180  https://spb.cian.ru/sale/flat/261053782/  150000.0  skapis\n",
      "22767       22768  https://spb.cian.ru/sale/flat/261935726/  121429.0  spryun\n",
      "22444       22445  https://spb.cian.ru/sale/flat/262417793/  223214.0  spryun\n",
      "10338       10339  https://spb.cian.ru/sale/flat/259129106/  177384.0  skryug\n",
      "13155       13156  https://spb.cian.ru/sale/flat/262525257/  195000.0  smozwy\n",
      "804           805  https://spb.cian.ru/sale/flat/259194918/  138900.0  sadkol\n",
      "18970       18971  https://spb.cian.ru/sale/flat/262743501/  221212.0  sprn65\n",
      "21243       21244  https://spb.cian.ru/sale/flat/261041315/  233333.0  sproze\n",
      "28099       28100  https://spb.cian.ru/sale/flat/261144927/  110754.0  spushu\n",
      "31551       31552  https://spb.cian.ru/sale/flat/262688402/   83459.0  lwswse\n",
      "4399         4400  https://spb.cian.ru/sale/flat/260387424/  151282.0  skan21\n",
      "12014       12015  https://spb.cian.ru/sale/flat/257553955/  198780.0  smogag\n",
      "22696       22697  https://spb.cian.ru/sale/flat/264049058/  145516.0  spryun\n",
      "23239       23240  https://spb.cian.ru/sale/flat/261418052/  204433.0  swagaw\n"
     ]
    }
   ],
   "source": [
    "# create sample\n",
    "sam_size = 25\n",
    "ran_sam = df.sample(n=sam_size)\n",
    "print(ran_sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e45f3c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of unit price for random sample is 147030.5\n",
      "The maximum of unit price for random sample is 181481.0\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and maximum for the samle\n",
    "rs_mean = ran_sam['price_m'].mean()\n",
    "rs_max = ran_sam['price_m'].max()\n",
    "print(\"The mean of unit price for random sample is\", rs_mean)\n",
    "print(\"The maximum of unit price for random sample is\", rs_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae1e4c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20606    213889.0\n",
      "11160    161667.0\n",
      "21112    148830.0\n",
      "19612    189706.0\n",
      "5076     139382.0\n",
      "13890    231935.0\n",
      "12315    198765.0\n",
      "8250     181985.0\n",
      "243      210697.0\n",
      "15608    134454.0\n",
      "7387     108974.0\n",
      "5179     150000.0\n",
      "22767    121429.0\n",
      "22444    223214.0\n",
      "10338    177384.0\n",
      "13155    195000.0\n",
      "804      138900.0\n",
      "18970    221212.0\n",
      "21243    233333.0\n",
      "28099    110754.0\n",
      "31551     83459.0\n",
      "4399     151282.0\n",
      "12014    198780.0\n",
      "22696    145516.0\n",
      "23239    204433.0\n",
      "Name: price_m, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# obtain Jackknife resamples\n",
    "new_df = ran_sam[\"price_m\"]\n",
    "array = new_df.to_numpy()\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62136dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 148830. 189706. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 189706. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 151282. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 151282. 198780. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 151282. 198780. 145516.]]\n"
     ]
    }
   ],
   "source": [
    "# obtain Jackknife resamples\n",
    "resamples = jackknife_resampling(array)\n",
    "print(resamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7aae4bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 24)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain Jackknife resamples shape\n",
    "resamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c028f943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the jacked mean is  170999.2\n",
      "the bias got from the Jackknife is  23968.70000000001\n",
      "the standard error got from the Jackknife is  8468.584368318783\n",
      "the confident interval (95%) of jacked mean is  [154401.07963806 187597.32036194]\n"
     ]
    }
   ],
   "source": [
    "# obtain Jackknife estimate for the mean, its bias,\n",
    "# its standard error, and its 95% confidence interval\n",
    "test_statistic = np.mean\n",
    "\n",
    "estimate, bias, stderr, conf_interval = jackknife_stats(\n",
    "    array, test_statistic, 0.95)\n",
    "\n",
    "mean_jacked = estimate\n",
    "print(\"the jacked mean is \", mean_jacked)\n",
    "bias_jack = abs(mean_jacked - rs_mean)\n",
    "print(\"the bias got from the Jackknife is \", bias_jack)\n",
    "std_error = stderr\n",
    "print(\"the standard error got from the Jackknife is \", std_error)\n",
    "conf_int = conf_interval\n",
    "print(\"the confident interval (95%) of jacked mean is \", conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd2b6b",
   "metadata": {},
   "source": [
    "Aomo podemos ver, la expectativa es 176116,525, la media muestral es 147030,500 y la media ajustada obtenida por el método Jackknife es 170999,200. El intervalo de confianza para la expectativa es [154401.080, 187597.320] con una probabilidad de 0,95. Así, demostramos de forma inequívoca que la aplicación del método Jackknife conduce a una mejora significativa de la precisión de la estimación del parámetro de distribución. Además, el intervalo de confianza calculado incluye el verdadero valor de la expectativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057f3e1",
   "metadata": {},
   "source": [
    "## Epílogo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf1ae8",
   "metadata": {},
   "source": [
    "El método Jackknife es una herramienta sencilla y computacionalmente eficaz para el ajuste de los estimadores muestrales. Espero que su aplicación ayude a muchos tasadores en su práctica diaria. Y tal vez inspire a alguien a utilizar más ampliamente los métodos de aprendizaje automático en las actividades de valoración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4dbca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
