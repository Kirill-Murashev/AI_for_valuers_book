{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00683ed",
   "metadata": {},
   "source": [
    "# Overcoming the problem of biased estimates while analyzing open markets data by the Jackknife resampling method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b4eb2",
   "metadata": {},
   "source": [
    "Cyrill A. Murashev, 2023-02-03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc51b3",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3067f10",
   "metadata": {},
   "source": [
    "Appraisers often face the need to analyze and describe market data collected on the open markets. Almost always they can't get the data about the whole market, but they deal with samples, which could be very small relatively to the whole general population. In this case, the problem of biased estimates arises. It follows from the above that any statistical estimate made on the basis of the sample in question is an estimate for the sample itself. At the same time, it may have a bias relative to the estimate that would be obtained in the case of an analysis of the entire general population. Appraisers often say that they calculated some descriptive statistics of the market. It can be the price mean or median, maximum, and minimum, etc. But we should understand that they are just estimates for samples, not for the entire market. Today we will consider the minimum theoretical basis of the method. And then we implement it to real market data using the Python language. We will learn how to determine for any estimation whether bias exists and how to automatically reduce its linear component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b687ef4",
   "metadata": {},
   "source": [
    "## Basis of the Jackknife method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10984e68",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b4ef7",
   "metadata": {},
   "source": [
    "First, we need to recall why appraisers need statistic. Usually they have some distribution of the features of objects from the sample of analogues collected on the open market. And they try to get some estimations of the values of that features. It can be mean, median, maximum, minimum, variance, etc. Sometimes they also need to compare two or more subsamples to decide whether some adjustments are required based on the difference of feature values. As we can guess, more often than not appraisers deal with samples, not with the entire market. Thus, appraisers can get only sampling estimates of the features values, but not their true values. \n",
    "The method of Jackknife can manage two issues:\n",
    "- reduce the bias of the sampling estimation relative to the true value from the general population;\n",
    "- calculate the variance of the adjusted feature value.\n",
    "\n",
    "Suppose we have some feature X (it could be unit price, for example), the distribution of which in the general population is unknown to us. But we have a sample consisting of n elements $[x{1},\\ldots, x_{n}]$. We want to estimate the expectation of X which can be written as $\\mathbb{E}[X]$. In general, the expectation can be notated as following\n",
    "$$\\mathbb{E}[X] = \\sum_{j=1}^{n >> 1} p(x_{j})x_{j}.$$\n",
    "\n",
    "But we have only a sample that of course consists of very limited number of observations far from infinity. So we are not able to estimate the expectation, only the sampling mean which is notated as\n",
    "$$\\hat{\\mu}=\\dfrac{1}{n} \\sum_{i=1}^{n<<\\infty}x_{i}.$$\n",
    "\n",
    "Therefore, we do not use probabilities, but observed frequencies. It's obvious that $\\mathbb{E}[X] \\neq \\hat{\\mu}$, but $\\hat{\\mu} = \\mathbb{E}[X] + \\mathcal{bias}$, where $\\mu$ is the estimation of the expectation, and the bias is some systematic shift between true and estimated values of the expectation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7de898",
   "metadata": {},
   "source": [
    "### General concept of Jacknife method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845785ef",
   "metadata": {},
   "source": [
    "We have considered a special case. We can now move on to the more general concept of estimator's bias. Let's consider the random variable *X* having the unknown distribution *U*. There is some parameter of its distribution named as $\\theta$. And we aim to determine its value. Using the abstract parameter Theta instead of a specific one emphasizes the universality of the Jackknife method, which is able to detect bias for any parameter of distribution and automatically correct its linear component. We also have parameter $\\hat{\\theta}$, which is the sampling estimation got from using some function. Due to the fact that $\\hat{\\theta}$ was got from a sample, while we aim to estimate $\\theta$ for the general population, that is the entire market in the context of valuation, $\\hat{\\theta}$ has a bias relative to $\\theta$. Mathematically, it means that the expectation for $\\hat{\\theta}$ is not equal to the expectation for $\\theta$:\n",
    "$$\\mathbb{E}(\\hat{\\theta}) \\neq \\mathbb{E}(\\theta).$$\n",
    "In this case, we can say that\n",
    "$$\\mathbb{E}(\\hat{\\theta}_{n}) = \\theta + \\frac{\\alpha}{n} + \\frac{\\beta}{n^{2}} + \\frac{\\gamma}{n^{3}} + \\ldots \\frac{\\omega}{n^{(k\\rightarrow \\infty)}},$$\n",
    "where $\\theta$ is the true value of the parameter for general population, and  $\\frac{\\alpha}{n} + \\frac{\\beta}{n^{2}} + \\frac{\\gamma}{n^{3}} + \\ldots \\frac{\\omega}{n^{(k\\rightarrow \\infty)}}$ are linear, quadratic, cubic and other components of bias. All components decrease with the growth of the sample in accordance with linear, quadratic, cubic and other functions. The linear term introduces the largest error because it decreases the slowest of all the others.\n",
    "\n",
    "The Jackknife method eliminates the linear component of bias. Let's introduce a new definitions.\n",
    "\n",
    "$\\hat{\\theta}_{i}$ is the value of $\\hat{\\theta}$ that would be obtained when calculating not on a full sample, but on a sample with an excluded observation *i*, which takes values from 1 to *n*. Then\n",
    "$$\\mathbb{E}(\\hat{\\theta}_{(i)}) = \\theta + \\frac{\\alpha}{n-1} + \\frac{\\beta}{(n-1)^{2}} + \\frac{\\gamma}{(n-1)^{3}} + \\ldots \\frac{\\omega}{(n-1)^{(k\\rightarrow \\infty)}}.$$\n",
    "$\\overline{\\theta}$ is the mean value of all $\\hat{\\theta}_{i}$.\n",
    "$$\\overline{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\theta}_{i}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709fcf5",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53e0e8",
   "metadata": {},
   "source": [
    "So, to apply the Jackknife method, i.e., detecting the presence of a bias and automatically eliminating its linear component, the following set of steps is required.\n",
    "1. Let us need to estimate some parameter $\\theta$ of a random variable *X*.\n",
    "1. Let's get some estimate of $\\hat{\\theta}$ for the sample using some mathematical function $\\hat{\\theta}=F(x_{1},\\ldots,x_{n})$.\n",
    "1. $\\hat{\\theta}$ can be biased.\n",
    "1. $\\theta = \\mathbb{E}(\\hat{\\theta}) + bias$.\n",
    "1. Let's create the new *n* samples by sequentially exclusion of one *x* from the initial sample.\n",
    "1. Calculate the $\\hat{\\theta}_{(i)}$ for all new samples using the same function **F**.\n",
    "1. Calculate the mean of all $\\hat{\\theta}_{(i)}$ and denote it as $\\overline{\\theta}$.\n",
    "1. Calculate the bias using the following formula\n",
    "$$\\widehat{bias}_{jack} = (n-1)(\\overline{\\theta} - \\hat{\\theta}).$$\n",
    "1. Eliminate the linear component of bias by using the formula\n",
    "$$\\hat{\\theta}_{jacked} = \\hat{\\theta} - \\widehat{bias}_{jack}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88cf6e",
   "metadata": {},
   "source": [
    "## Practical implementation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e084ff",
   "metadata": {},
   "source": [
    "Today we will use dataset containing 34821 observations of residential real market in St. Petersburg. It was got from web-scrapping in September 2021. Let's assume that this dataset contains data about the entire market, so we can use it as a general population. Next, we will create subsample containing only 25 observations, which reflects the typical number of observations that an appraiser deals. We will calculate “the expectation” for our “general population”, then we will calculate the mean for the sample. At last, we will apply the Jackknife method and compare its result of mean calculating relative to sampling mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df71016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats import jackknife_resampling\n",
    "from astropy.stats import jackknife_stats\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "805cc253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                     links   price_m  county\n",
      "0               1  https://spb.cian.ru/sale/flat/262765174/  155460.0  sadadm\n",
      "1               2  https://spb.cian.ru/sale/flat/263280601/  295455.0  sadadm\n",
      "2               3  https://spb.cian.ru/sale/flat/261612519/  310559.0  sadadm\n",
      "3               4  https://spb.cian.ru/sale/flat/263094016/  100000.0  sadadm\n",
      "4               5  https://spb.cian.ru/sale/flat/262339898/  145929.0  sadadm\n",
      "...           ...                                       ...       ...     ...\n",
      "34816       34817  https://spb.cian.ru/sale/flat/256621764/   70093.0  llobol\n",
      "34817       34818  https://spb.cian.ru/sale/flat/261430727/   67227.0  llobol\n",
      "34818       34819  https://spb.cian.ru/sale/flat/246538655/   86207.0  llobol\n",
      "34819       34820  https://spb.cian.ru/sale/flat/246587468/   65455.0  llobol\n",
      "34820       34821  https://spb.cian.ru/sale/flat/239698989/   89041.0  llobol\n",
      "\n",
      "[34821 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"spba-flats-210928.csv\", index_col=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9899bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of unit price for 'general population' is 176116.52505671864\n",
      "The maximum of unit price for 'general population' is 1624829.0\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and maximum for the \"general population\"\n",
    "gp_mean = df['price_m'].mean()\n",
    "gp_max = df['price_m'].max()\n",
    "print(\"The mean of unit price for 'general population' is\", gp_mean)\n",
    "print(\"The maximum of unit price for 'general population' is\", gp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c32eb719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                                     links   price_m  county\n",
      "20606       20607  https://spb.cian.ru/sale/flat/264064476/  213889.0  sprkol\n",
      "11160       11161  https://spb.cian.ru/sale/flat/261519367/  161667.0  skryuz\n",
      "21112       21113  https://spb.cian.ru/sale/flat/263895261/  148830.0  sprlax\n",
      "19612       19613  https://spb.cian.ru/sale/flat/250041085/  189706.0  sprn65\n",
      "5076         5077  https://spb.cian.ru/sale/flat/263660571/  139382.0  skapis\n",
      "13890       13891  https://spb.cian.ru/sale/flat/263013521/  231935.0  smonow\n",
      "12315       12316  https://spb.cian.ru/sale/flat/262914352/  198765.0  smozwy\n",
      "8250         8251  https://spb.cian.ru/sale/flat/263518941/  181985.0  skrpol\n",
      "243           244  https://spb.cian.ru/sale/flat/251281327/  210697.0  sadeka\n",
      "15608       15609  https://spb.cian.ru/sale/flat/260189091/  134454.0  snenew\n",
      "7387         7388  https://spb.cian.ru/sale/flat/257597416/  108974.0  skomet\n",
      "5179         5180  https://spb.cian.ru/sale/flat/261053782/  150000.0  skapis\n",
      "22767       22768  https://spb.cian.ru/sale/flat/261935726/  121429.0  spryun\n",
      "22444       22445  https://spb.cian.ru/sale/flat/262417793/  223214.0  spryun\n",
      "10338       10339  https://spb.cian.ru/sale/flat/259129106/  177384.0  skryug\n",
      "13155       13156  https://spb.cian.ru/sale/flat/262525257/  195000.0  smozwy\n",
      "804           805  https://spb.cian.ru/sale/flat/259194918/  138900.0  sadkol\n",
      "18970       18971  https://spb.cian.ru/sale/flat/262743501/  221212.0  sprn65\n",
      "21243       21244  https://spb.cian.ru/sale/flat/261041315/  233333.0  sproze\n",
      "28099       28100  https://spb.cian.ru/sale/flat/261144927/  110754.0  spushu\n",
      "31551       31552  https://spb.cian.ru/sale/flat/262688402/   83459.0  lwswse\n",
      "4399         4400  https://spb.cian.ru/sale/flat/260387424/  151282.0  skan21\n",
      "12014       12015  https://spb.cian.ru/sale/flat/257553955/  198780.0  smogag\n",
      "22696       22697  https://spb.cian.ru/sale/flat/264049058/  145516.0  spryun\n",
      "23239       23240  https://spb.cian.ru/sale/flat/261418052/  204433.0  swagaw\n"
     ]
    }
   ],
   "source": [
    "# create sample\n",
    "sam_size = 25\n",
    "ran_sam = df.sample(n=sam_size)\n",
    "print(ran_sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e45f3c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of unit price for random sample is 147030.5\n",
      "The maximum of unit price for random sample is 181481.0\n"
     ]
    }
   ],
   "source": [
    "# calculate mean and maximum for the samle\n",
    "rs_mean = ran_sam['price_m'].mean()\n",
    "rs_max = ran_sam['price_m'].max()\n",
    "print(\"The mean of unit price for random sample is\", rs_mean)\n",
    "print(\"The maximum of unit price for random sample is\", rs_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae1e4c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20606    213889.0\n",
      "11160    161667.0\n",
      "21112    148830.0\n",
      "19612    189706.0\n",
      "5076     139382.0\n",
      "13890    231935.0\n",
      "12315    198765.0\n",
      "8250     181985.0\n",
      "243      210697.0\n",
      "15608    134454.0\n",
      "7387     108974.0\n",
      "5179     150000.0\n",
      "22767    121429.0\n",
      "22444    223214.0\n",
      "10338    177384.0\n",
      "13155    195000.0\n",
      "804      138900.0\n",
      "18970    221212.0\n",
      "21243    233333.0\n",
      "28099    110754.0\n",
      "31551     83459.0\n",
      "4399     151282.0\n",
      "12014    198780.0\n",
      "22696    145516.0\n",
      "23239    204433.0\n",
      "Name: price_m, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# obtain Jackknife resamples\n",
    "new_df = ran_sam[\"price_m\"]\n",
    "array = new_df.to_numpy()\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62136dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 148830. 189706. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 189706. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 139382. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 231935. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 198765. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 181985. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 210697. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 134454.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 150000. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 121429. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 223214. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 177384. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 195000. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 138900. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 221212. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 233333.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  110754.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333.  83459. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754. 151282. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 198780. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 151282. 145516. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 151282. 198780. 204433.]\n",
      " [213889. 161667. 148830. 189706. 139382. 231935. 198765. 181985. 210697.\n",
      "  134454. 108974. 150000. 121429. 223214. 177384. 195000. 138900. 221212.\n",
      "  233333. 110754.  83459. 151282. 198780. 145516.]]\n"
     ]
    }
   ],
   "source": [
    "# obtain Jackknife resamples\n",
    "resamples = jackknife_resampling(array)\n",
    "print(resamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7aae4bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 24)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain Jackknife resamples shape\n",
    "resamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c028f943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the jacked mean is  170999.2\n",
      "the bias got from the Jackknife is  23968.70000000001\n",
      "the standard error got from the Jackknife is  8468.584368318783\n",
      "the confident interval (95%) of jacked mean is  [154401.07963806 187597.32036194]\n"
     ]
    }
   ],
   "source": [
    "# obtain Jackknife estimate for the mean, its bias,\n",
    "# its standard error, and its 95% confidence interval\n",
    "test_statistic = np.mean\n",
    "\n",
    "estimate, bias, stderr, conf_interval = jackknife_stats(\n",
    "    array, test_statistic, 0.95)\n",
    "\n",
    "mean_jacked = estimate\n",
    "print(\"the jacked mean is \", mean_jacked)\n",
    "bias_jack = abs(mean_jacked - rs_mean)\n",
    "print(\"the bias got from the Jackknife is \", bias_jack)\n",
    "std_error = stderr\n",
    "print(\"the standard error got from the Jackknife is \", std_error)\n",
    "conf_int = conf_interval\n",
    "print(\"the confident interval (95%) of jacked mean is \", conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd2b6b",
   "metadata": {},
   "source": [
    "As we can see, the expectation is 176116.525, the sampling mean is 147030.500, and the adjusted mean got by the Jackknife method is 170999.200. The confidence interval for the expectation is [154401.080, 187597.320] with probability of 0.95. So, we can Thus, we unequivocally proved that the application of the Jackknife method leads to a significant improvement in the accuracy of the distribution parameter estimate. Moreover, the calculated confidence interval includes the true value of the expectation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057f3e1",
   "metadata": {},
   "source": [
    "## Afterword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf1ae8",
   "metadata": {},
   "source": [
    "The Jackknife method is a simple and computationally effective tool for adjusting of sampling estimators. I hope that its application will help to many appraisers in their everyday practice. And perhaps it will inspire someone to more widely use machine learning methods in valuation activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4dbca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
